{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение, ЭФ МГУ\n",
    "\n",
    "## Практическое задание 3. Линейные методы классификации. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### О задании\n",
    "\n",
    "В этом задании вы:\n",
    "- ознакомитесь с тем, что происходит \"внутри\" метода опорных векторов и логистической регрессии\n",
    "- познакомитесь с калибровкой вероятности\n",
    "- изучите методы трансформации переменных и методы отбора признаков\n",
    "- попробуете оценить экономический эффект модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (8, 8)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пропишите путь до папки c данными:\n",
    "DATA_PATH = '/Users/tony/Desktop/Pracs ML EF/Linear methods/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 0. SVM, LR и калибровка вероятностей. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем синтетические данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=10000, n_features=10, n_informative=5, n_redundant=5,\n",
    "    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__ Обучение и применение метода опорных векторов и логистической регрессии.\n",
    "\n",
    "__(1 балл)__\n",
    "\n",
    "Обучите метод опорных векторов. На занятиях мы проходили линейный вариант без ядрового перехода, что соответствует линейному ядру (`LinearSVC` или же `SVC(kernel='linear')` в `sklearn.svm`). Подберите параметр регуляризации `C` (можете воспользоваться кросс-валидацией или отделить валидационную выборку от обучающей). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import cross_val_score, KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тестовой части посчитайте AUC-ROC, AUC-PR с точностью до 5 знаков. Постройте ROC и PR кривые, сравните их с ответами случайного классификатора. Заметим, что с помощью `sklearn` можно посчитать обе метрики двумя разными способами - в чем их различия? Сравните результаты. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь проделайте все то же самое для логистической регрессии (LR) — обучение, подбор параметра регуляризации (используйте L2-регуляризацию), вычисление всех метрик и построение кривых. Сравните результаты LR и SVM с точки зрения всех вычисленных критериев качества, объясните различия (если они есть)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В названии метода опорных векторов присутствуют некоторые \"опорные векторы\". Сгенерируйте синтетический датасет с помощью `make_classification` с 2 признаками, обучите на нём метод опорных векторов. Визуализируйте разделяющую прямую, все объекты и выделите опорные вектора (атрибут `support_vectors_`). В этот раз, если необходимо, вместо `LinearSVC` воспользуйтесь `SVC(kernel='linear')`, так как только в нём есть информация об опорных векторах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "from sklearn.datasets import make_moons\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличие от метода опорных векторов, логистическая регрессия не пытается построить разделяющую гиперплоскость, а приближает в каждой точке пространства объектов правдоподобие положительных ответов $p(y=+1|x)$. Попробуйте нарисовать это распределение на плоскости, не забудьте отметить на ней все объекты. Вам может помочь функция `plot_2d_separator` (реализованная ниже)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_separator(clf: object, X: np.array, y: np.array=None, draw_points: bool=True, **kwargs):\n",
    "    min_x, max_x, min_y, max_y = (\n",
    "        np.min(X[:, 0]), np.max(X[:, 0]), np.min(X[:, 1]), np.max(X[:, 1])\n",
    "    )\n",
    "    std_x, std_y = np.std(X[:, 0]), np.std(X[:, 1])\n",
    "    x, y_ = np.meshgrid(\n",
    "        np.linspace(min_x - 0.1*std_x, max_x + 0.1*std_x, 200), \n",
    "        np.linspace(min_x - 0.1*std_x, max_x + 0.1*std_x, 200)\n",
    "    )\n",
    "    z = np.zeros_like(x)\n",
    "    if hasattr(clf, 'predict_proba'):\n",
    "        for i in tqdm(range(x.shape[0])):\n",
    "            for j in range(x.shape[1]):\n",
    "                z[i, j] = clf.predict_proba([[x[i, j], y_[i, j]]])[:, 1].item()\n",
    "    else:\n",
    "        for i in tqdm(range(x.shape[0])):\n",
    "            for j in range(x.shape[1]):\n",
    "                z[i, j] = clf.decision_function([[x[i, j], y_[i, j]]]).item()\n",
    "    z = z[:-1, :-1]\n",
    "    z -= z.mean() # чтобы было 2 цвета\n",
    "    z_min, z_max = -np.abs(z).max(), np.abs(z).max()\n",
    "    plt.pcolor(x, y_, z, cmap='coolwarm', vmin=z_min, vmax=z_max);\n",
    "    if draw_points:\n",
    "        if y is None:\n",
    "            plt.scatter(X[:, 0], X[:, 1], **kwargs);\n",
    "        else:\n",
    "            if 'color' in kwargs:\n",
    "                del kwargs['color']\n",
    "            plt.scatter(X[:, 0], X[:, 1], color=np.array(['blue', 'red'])[y], **kwargs);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2.__ Калибровка вероятностей.\n",
    "\n",
    "__(1 балл)__\n",
    "\n",
    "Перейдём к оценке качества выдаваемых алгоритмами вероятностей. Начнём с калибровочных кривых. \n",
    "\n",
    "Допустим, алгоритм возвращает некоторые числа от нуля до единицы. Хорошо ли они оценивают вероятность? Для этого разобьем отрезок $[0, 1]$ на несколько маленьких отрезков одинаковой длины. Рассмотрим $i$-й отрезок с границами $[a_i, b_i]$ и предсказания $p_1, p_2, \\dots, p_k$, которые попали в него. Пусть им соответствуют истинные ответы $y_1, y_2, \\dots, y_k$. Если алгоритм выдает корректные вероятности, то среди этих истинных ответов должно быть примерно $(a_i + b_i) / 2$ единиц. Иными словами, если нарисовать кривую, у которой по оси X отложены центры отрезков, а по оси Y — доли единичных ответов этих в отрезках, то она должна оказаться диагональной. Ниже приведена функция, которая должна рисовать такие кривые. В ней допущено две ошибки — найдите и исправьте их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_calibration_curve(y_test, preds, label: str=None, color: str='blue'):\n",
    "    bin_middle_points = []\n",
    "    bin_real_ratios = []\n",
    "    n_bins = 10\n",
    "    for i in range(n_bins):\n",
    "        l = 1.0 / n_bins * i\n",
    "        r = 1.0 / n_bins * (i + 1)\n",
    "        bin_middle_points.append((r - l) / 2) \n",
    "        bin_real_ratios.append(np.mean(y_test[(preds >= l) & (preds > r)] == 1)) \n",
    "    plt.plot(bin_middle_points, bin_real_ratios, label=label, color=color)\n",
    "    plt.scatter(bin_middle_points, bin_real_ratios, color=color)\n",
    "    if label is not None:\n",
    "        plt.legend(fontsize=13);\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируйте синтетический датасет аналогично использованному в самом первом задании. Постройте калибровочные кривые на тестовой части для логистической регрессии и метода опорных векторов (не забудьте перевести его предсказания в $[0;1]$). Изучите распределение ответов классификаторов (постройте гистограммы, например можете использовать `plt.hist` или `sns.distplot`). Чем они различаются? Чем вы можете объяснить это?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуйтесь `CalibratedClassifierCV` из `sklearn` для калибровки вероятностей метода опорных векторов на обучении и постройте с его помощью предсказания для тестовой выборки. Нарисуйте для них калибровочную кривую. Улучшилась ли она?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "from sklearn.calibration import CalibratedClassifierCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Бонусное задание (0.5 балла).__ Реализуйте свою функцию для калибровки вероятностей. Опишите ваш подход и продемонстрируйте результаты. Ключевые слова для вдохновения: `Platt`, `Isotonic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 1. Работа с переменными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части мы научимся обрабатывать категориальные переменные, так как закодировать их в виде чисел недостаточно (это задаёт некоторый порядок, которого на категориальных переменных может и не быть). Существует два основных способа обработки категориальных значений:\n",
    "- One-hot-кодирование\n",
    "- Счётчики (CTR, mean-target кодирование, ...) — каждый категориальный признак заменяется на среднее значение целевой переменной по всем объектам, имеющим одинаковое значение в этом признаке.\n",
    "\n",
    "Начнём с one-hot-кодирования. Допустим наш категориальный признак $f_j(x)$ принимает значения из множества $C=\\{c_1, \\dots, c_m\\}$. Заменим его на $m$ бинарных признаков $b_1(x), \\dots, b_m(x)$, каждый из которых является индикатором одного из возможных категориальных значений:\n",
    "$$\n",
    "b_i(x) = [f_j(x) = c_i]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Подготовка данных.__\n",
    "\n",
    "Загрузим данные [UCI Bank Marketing Dataset](https://archive.ics.uci.edu/ml/datasets/bank+marketing). Этот датасет содержит информацию о банковском телефонном маркетинге, объектом в нем является телефонный звонок потенциальному клиенту с предложением некоторой услуги (утверждается, что это краткосрочный депозит), целевой переменной - ответ клиента (согласился ли он открыть депозит?). В качестве признакового описания используются характеристики клиента (образование, брак и т.д.), данные о звонке и различные экономические индикаторы - более подробная информация представлена в файле `bank-additional-names.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{DATA_PATH}/bank-additional-full.csv', sep=';')\n",
    "df.drop(['duration'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  campaign  pdays  previous     poutcome  emp.var.rate  \\\n",
       "0   may         mon         1    999         0  nonexistent           1.1   \n",
       "1   may         mon         1    999         0  nonexistent           1.1   \n",
       "2   may         mon         1    999         0  nonexistent           1.1   \n",
       "3   may         mon         1    999         0  nonexistent           1.1   \n",
       "4   may         mon         1    999         0  nonexistent           1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  "
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__age__ (numeric)\n",
    "\n",
    "__job__ : type of job (categorical: \"admin.\",\"blue-collar\",\"entrepreneur\",\"housemaid\",\"management\",\"retired\",\"self-employed\",\"services\",\"student\",\"technician\",\"unemployed\",\"unknown\")\n",
    "\n",
    "__marital__ : marital status (categorical: \"divorced\",\"married\",\"single\",\"unknown\"; note: \"divorced\" means divorced or widowed)\n",
    "\n",
    "__education__ (categorical: \"basic.4y\",\"basic.6y\",\"basic.9y\",\"high.school\",\"illiterate\",\"professional.course\",\"university.degree\",\"unknown\")\n",
    "\n",
    "__default__: has credit in default? (categorical: \"no\",\"yes\",\"unknown\")\n",
    "\n",
    "__housing__: has housing loan? (categorical: \"no\",\"yes\",\"unknown\")\n",
    "\n",
    "__loan__: has personal loan? (categorical: \"no\",\"yes\",\"unknown\")\n",
    "### related with the last contact of the current campaign:\n",
    "__contact__: contact communication type (categorical: \"cellular\",\"telephone\") \n",
    "\n",
    "__month__: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n",
    "\n",
    "__day_of_week__: last contact day of the week (categorical: \"mon\",\"tue\",\"wed\",\"thu\",\"fri\")\n",
    "\n",
    "__duration__: last contact duration, in seconds (numeric). Important note:  this attribute highly affects the output target (e.g., if duration=0 then y=\"no\"). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "### other attributes:\n",
    "__campaign__: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "\n",
    "__pdays__: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "\n",
    "__previous__: number of contacts performed before this campaign and for this client (numeric)\n",
    "\n",
    "__poutcome__: outcome of the previous marketing campaign (categorical: \"failure\",\"nonexistent\",\"success\")\n",
    "### social and economic context attributes\n",
    "__emp.var.rate__: employment variation rate - quarterly indicator (numeric)\n",
    "\n",
    "__cons.price.idx__: consumer price index - monthly indicator (numeric)     \n",
    "__cons.conf.idx__: consumer confidence index - monthly indicator (numeric)     \n",
    "__euribor3m__: euribor 3 month rate - daily indicator (numeric)\n",
    "\n",
    "__nr.employed__: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "### Output variable (desired target):\n",
    "\n",
    "__y__ - has the client subscribed a term deposit? (binary: \"yes\",\"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 3 (0.5 балла).__ Разделите выборку на обучающую и тестовую в соотношении 3:1. Зафиксируйте `random_state=777`, также используйте `stratify`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30891, 20) (10297, 20)\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "RANDOM_STATE = 777\n",
    "df_train, df_test = train_test_split(df, test_size=0.25, stratify=df['y'].values, random_state=RANDOM_STATE)\n",
    "y_train = (df_train['y'].values == 'yes').astype(int)\n",
    "y_test = (df_test['y'].values == 'yes').astype(int)\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Проверка, что данные разделились с одинаковым распределением таргета\n",
    "tmp_train = df_train['y'].value_counts(1).to_dict()\n",
    "tmp_test = df_test['y'].value_counts(1).to_dict()\n",
    "plt.title(f'Распределение таргета в обучении и в тесте', fontsize=15);\n",
    "plt.bar(['no', 'yes'], [tmp_train['no'], tmp_train['yes']], color='dodgerblue', alpha=0.5, label='train');\n",
    "plt.bar(['no', 'yes'], [tmp_test['no'], tmp_test['yes']], color='red', alpha=0.5, label='test');\n",
    "plt.legend(fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закодируйте категориальные признаки с помощью `OrdinalEncoder`. Посчитайте качество (в этом задании будем работать c `AUC-PR`) при применении логистической регрессии. Замерьте время, потребовавшееся на обучение модели (с учетом кодирования признаков).\n",
    "\n",
    "__Вопрос__: почему в данном задании мы выбрали метрикой именно `AUC-PR`, а не, к примеру, `AUC-ROC`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ваш ответ__: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-PR на тесте: 0.4161175190051784\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import auc, precision_recall_curve\n",
    "\n",
    "X_train = df_train.drop(['y'], axis=1).copy()\n",
    "X_test = df_test.drop(['y'], axis=1).copy()\n",
    "\n",
    "for feature in X_train.columns[(X_train.dtypes == 'object')]:\n",
    "    ordinal_enc = OrdinalEncoder()\n",
    "    ordinal_enc.fit(X_train[feature].values.reshape(-1, 1))\n",
    "    X_train[feature] = ordinal_enc.transform(X_train[feature].values.reshape(-1, 1))\n",
    "    X_test[feature] = ordinal_enc.transform(X_test[feature].values.reshape(-1, 1))\n",
    "    \n",
    "    \n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pr, rec, thresholds = precision_recall_curve(y_true=y_test, probas_pred=model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(\n",
    "    'AUC-PR на тесте:',\n",
    "    #your code here\n",
    "    auc(rec, pr)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 4 (0.5 балла).__ Закодируйте все категориальные признаки с помощью one-hot-кодирования. Обучите логистическую регрессию и посмотрите, как изменилось качество модели (с тем, что было до кодирования). Измерьте время, потребовавшееся на кодирование категориальных признаков и обучение модели.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEnc обучился и применился за 0.0 минут 0.24 секунд\n",
      "Модель обучилась за 0.0 минут 0.58 секунд\n",
      "AUC-PR на тесте: 0.4353890716489632\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "#your code here\n",
    "import time\n",
    "from itertools import chain\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X_train = df_train.drop(['y'], axis=1).copy()\n",
    "X_test = df_test.drop(['y'], axis=1).copy()\n",
    "cat_cols = X_train.columns[X_train.dtypes == 'object'].values\n",
    "noncat_cols = X_train.columns[X_train.dtypes != 'object'].values\n",
    "\n",
    "st = time.perf_counter() \n",
    "ohe_enc = OneHotEncoder()\n",
    "ohe_enc.fit(X_train[cat_cols])\n",
    "cat_ohe_names = list(chain.from_iterable(\n",
    "    [[f'{col}_{category}' for category in ohe_enc.categories_[i]] for i, col in \n",
    "     enumerate(cat_cols)]\n",
    "))\n",
    "\n",
    "X_train = pd.concat([\n",
    "    X_train[noncat_cols].reset_index(drop=True),\n",
    "    pd.DataFrame(ohe_enc.transform(X_train[cat_cols]).toarray(), \n",
    "                 columns=cat_ohe_names)\n",
    "], axis=1)\n",
    "\n",
    "X_test = pd.concat([\n",
    "    X_test[noncat_cols].reset_index(drop=True),\n",
    "    pd.DataFrame(ohe_enc.transform(X_test[cat_cols]).toarray(), \n",
    "                 columns=cat_ohe_names)\n",
    "], axis=1)\n",
    "\n",
    "end = time.perf_counter() - st\n",
    "print(f'OneHotEnc обучился и применился за {end // 60} минут {round(end % 60, 2)} секунд')\n",
    "    \n",
    "    \n",
    "st = time.perf_counter() \n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "end = time.perf_counter() - st\n",
    "print(f'Модель обучилась за {end // 60} минут {round(end % 60, 2)} секунд')\n",
    "\n",
    "pr, rec, thresholds = precision_recall_curve(y_true=y_test, probas_pred=model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(\n",
    "    'AUC-PR на тесте:',\n",
    "    #your code here\n",
    "    auc(rec, pr)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно было заменить, one-hot-кодирование может сильно увеличивать количество признаков в датасете, что сказывается на памяти, особенно, если некоторый признак имеет большое количество значений. Эту проблему решает другой способ кодирования категориальных признаков — счётчики. Основная идея в том, что нам важны не сами категории, а значения целевой переменной, которые имеют объекты этой категории. Каждый категориальный признак мы заменим средним значением целевой переменной по всем объектам этой же категории:\n",
    "$$\n",
    "g_j(x, X) = \\frac{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)][y_i = +1]}{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)]}\n",
    "$$\n",
    "\n",
    "__Задание 5 (1 балл).__ Закодируйте категориальные переменные с помощью счётчиков (ровно так, как описано выше без каких-либо хитростей). Обучите логистическую регрессию и посмотрите на качество модели на тестовом множестве. Сравните время обучения с предыдущими экспериментами (с учетом кодирования признаков). Заметили ли вы что-то интересное?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отметим, что такие признаки сами по себе являются классификаторами и, обучаясь на них, мы допускаем \"утечку\" целевой переменной в признаки. Это ведёт к переобучению, поэтому считать такие признаки необходимо таким образом, чтобы при вычислении для конкретного объекта его целевая метка не использовалась. Это можно делать следующими способами:\n",
    "1. Вычислять значение счётчика по всем объектам расположенным выше в датасете (например, если у нас выборка отсортирована по времени).\n",
    "2. Вычислять по фолдам, то есть делить выборку на некоторое количество частей и подсчитывать значение признаков по всем фолдам кроме текущего (как делается в кросс-валидации).\n",
    "3. Внесение некоторого шума в посчитанные признаки. \n",
    "\n",
    "__Задание 6. (1 балл)__ Реализуйте корректное вычисление счётчиков самым простым способом — добавление шума к значениям (постарайтесь найти баланс между борьбой с переобучением и сохранением полезности признаков). Снова обучите логистическую регрессию, оцените качество. Сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь ответьте на следующий вопрос: что будет, если некоторая категория встречается в выборке всего несколько раз? По этой причине производится сглаживание счётчиков. Например, на практике хорошие результаты показывает использование сглаживания средним по всей выборке:\n",
    "$$\n",
    "g_j(x, X) = \\frac{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)][y_i = +1] + C \\times global\\_mean}{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)] + C}\n",
    "$$\n",
    "где $global\\_mean$ — доля объектов положительного класса в выборке, $C$ — параметр, определяющий степень сглаживания (например, можно использовать 10 или подобрать для каждого признака свой). Основная идея в том, что мы \"разбавляем\" среднее значение по некоторой категории глобальным средним значением. И тем меньше, чем большее количество объектов этой категории встречается в выборке. \n",
    "\n",
    "Однако для сглаживания вместо среднего значения целевой переменной можно использовать любое другое значение от 0 до 1 (этот параметр иногда называют $prior$). Можно сделать несколько признаков с разными значениями параметра. На практике в задачах бинарной классификации полезными бывают даже отрицательные значения!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 7 (1 балл).__ Добавьте сглаживание, описанное выше и повторите эксперименты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 8 (0.5 балла).__ В данных имеется признак \"возраст клиента\". Сейчас мы интерпретируем его как числовой, что в общем случае для линейной модели может быть неверной гипотезой. Тем не менее, у этого признака есть довольно много уникальных значений (сколько?), поэтому применять к нему one-hot кодирование может оказаться излишним. Попробуйте закодировать возраст с помощью счетчиков. Стало ли лучше?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно пойти и в обратную сторону. У нас есть признаки \"месяц и день недели\" для звонка. Попробуйте интерпретировать их как числовые (месяц от 0 до 12, дни недели от 0 до 4). Стало ли лучше в этот раз?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Замечание.__ Усложнение методов вычисления счётчиков не делают результаты модели гарантированно лучше. Особенно с учётом того, что логистическая регрессия не такая сложная модель, чтобы переобучаться. Поэтому вы необязательно должны были получать на каждом шаге всё лучшие и лучшие результаты (но необходимые результаты у вас должны были получиться).\n",
    "\n",
    "Как вы должны были заметить, счётчики являются хорошей альтернативой one-hot-кодированию. Напишите, какие плюсы и минусы использования счётчиков по сравнению с one-hot-кодированием вы заметили.\n",
    "\n",
    "__Ответ:__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 2. Отбор признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важной частью процесса построения модели является отбор признаков. На практике многие признаки оказывают малое влияние на модель (при этом их расчёт занимает время) или даже негативно сказываются на качестве модели. Попробуем несколько подходов отбора признаков, оценим, как они влияют на качество модели и сколько времени занимают.\n",
    "\n",
    "Обратимся к тому же датасету про банковский телефонный маркетинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{DATA_PATH}/bank-additional-full.csv', sep=';')\n",
    "\n",
    "X = df.drop(columns=['duration', 'y'])\n",
    "y = (df.y == 'yes').astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=777, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы помните, в данных много категориальных признаков (сейчас давайте интерпретировать возраст как числовой). Давайте закодируем их с помощью one-hot кодирования. Исходные колонки с категориальными признаками можно удалить. Сколько признаков мы получили?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "ohe_enc = OneHotEncoder()\n",
    "cat_cols = X_train.columns[X_train.dtypes == 'object'].values\n",
    "noncat_cols = X_train.columns[X_train.dtypes != 'object'].values\n",
    "ohe_enc.fit(X_train[cat_cols])\n",
    "cat_ohe_names = list(chain.from_iterable(\n",
    "    [[f'{col}_{category}' for category in ohe_enc.categories_[i]] for i, col in \n",
    "     enumerate(cat_cols)]\n",
    "))\n",
    "\n",
    "X_train = pd.concat([\n",
    "    X_train[noncat_cols].reset_index(drop=True),\n",
    "    pd.DataFrame(ohe_enc.transform(X_train[cat_cols]).toarray(), \n",
    "                 columns=cat_ohe_names)\n",
    "], axis=1)\n",
    "\n",
    "X_test = pd.concat([\n",
    "    X_test[noncat_cols].reset_index(drop=True),\n",
    "    pd.DataFrame(ohe_enc.transform(X_test[cat_cols]).toarray(), \n",
    "                 columns=cat_ohe_names)\n",
    "], axis=1)\n",
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве основной модели будем использовать логистическую регрессию, а целевой метрики — `AUC-PR`. Обучите модель и посчитайте качество на тестовой выборке. Давайте запомним полученное значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-PR на тесте: 0.4296945937978489\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pr, rec, thresholds = precision_recall_curve(y_true=y_test, probas_pred=model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(\n",
    "    'AUC-PR на тесте:',\n",
    "    #your code here\n",
    "    auc(rec, pr)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Встроенные методы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, мы хотим оставить только 40 лучших признаков. Попробуем сделать это несколькими способами.\n",
    "\n",
    "Начнём с отборам признаков с помощью линейной модели. Как известно, веса линейной модели означают вклад каждого признака в предсказание модели, а значит, модуль этого вклада можно интерпретировать как важность признаков. Такой метод отбора называются встроенным или embedded methods, так как он заложен в особенности модели.\n",
    "\n",
    "__Задание 8 (0.9 балла = 0.3 * 3).__ Оставьте 40 признаков с наибольшим модулем соответствующего параметра линейной модели. Обучите модели заново и оцените её качество. Замерьте скорость такого отбора признаков.\n",
    "\n",
    "Изменилось ли качество? Как?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь давайте подумаем, что мы не учли. Мы предположили, что признаки вносят вклад равномерно, но не учли их масштаба. Если мы умножим один из признаков в 100 раз, то без учёта регуляризации его вес уменьшится в эти же 100 раз. А мы на основе этого отбираем признаки! Давайте сначала отмасштабируем признаки одним из способов, а только потом будем удалять признаки. \n",
    "\n",
    "Кстати, в таком случае надо пересчитать качество на всех признаках (сделайте это ниже). Если вы сделали нормирование признаков в самом начале, то попробуйте отобрать признаки на неотмасштабированных данных.\n",
    "\n",
    "Что получилось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вопрос на засыпку: one-hot кодирование возвращает нам единичные признаки-индикаторы. Попробуйте также отскалировать их, как и обычные числовые, и снова выбрать 40 главных по вкладу признаков. Изменился ли их список? Изменится ли качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Методы фильтрации\n",
    "\n",
    "\n",
    "Давайте отбирать признаки умнее, а именно через подсчёт некоторой функции для каждого признака. На основании значений этой функции будем оставлять наиболее важные признаки. Методы этого семейства называют фильтрующими или  filter methods. \n",
    "\n",
    "В качестве такой функции будем считать t-статистику:\n",
    "\n",
    "$$t(j) = \\frac{|\\mu_+ - \\mu_-|}{\\sqrt{\\frac{n_+ \\sigma^2_+ + n_- \\sigma^2_-}{n_+ + n_-}}},$$\n",
    "\n",
    "где $\\mu$, $\\sigma$, $n$ соответственно среднее, стандартное отклонение и количество объектов каждого из классов.\n",
    "\n",
    "__Задание 9 (0.5 балла).__ Оставьте 40 признаков с наибольшим значением $t$ и замерьте качество. Не забудьте замерить скорость отбора признаков в этом случае.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Методы-обёртки\n",
    "\n",
    "__Задание 10 (1 балл).__ \n",
    "\n",
    "Третий из рассматриваемых нами методов работает следующим образом: мы исключаем по очереди один из признаков и смотрим, как это влияет на качество. Удаляем признаки таким жадным способом, пока не окажется выполненым некоторое условие (количество признаков или ухудшение качества).\n",
    "\n",
    "Заметим, что нельзя оценивать качество по тестовой выборке, иначе мы можем переобучиться, как, например, при настройке гиперпараметров. Разделите обучающую выборку на 2 части, на одной из них обучайте модель без одного из признаков,  на второй части оценивайте качество. Исходную тестовую выборку стоит использовать только для финальной оценки качества.\n",
    "\n",
    "Снова оставьте только 40 признаков и оцените качество на тестовой выборке. Сколько времени занял такой отбор признаков?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит отметить, что с помощью такого метода можно пойти и в обратную сторону. Попробуйте _добавлять_ по одному самому полезному признаку в выборку до тех пор, пока не наберется 40 штук. Найдется ли порог, при котором добавление следующих признаков будет только ухудшать качество модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте подведём итоги по отбору признаков. Назовите преимущества и недостатки каждого из методов. Какой метод привёл к наилучшему качеству?\n",
    "\n",
    "**Ответ:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 3. Оценка экономического эффекта модели\n",
    "\n",
    "В данной части мы займемся тем, что от вас скорее всего потребуется на реальной работе. А именно: мы соберем несколько специализированных метрик качества, попытаемся настроить модель на максимизацию _прибыли_ и оценим, сколько вообще получится заработать на этом. Разумеется, здесь будет сделано множество упрощающих жизнь допущений, но обо всем по порядку. \n",
    "\n",
    "__Задание 11 (1 балл).__ Допустим, работники вашего колл-центра получают за один звонок клиенту 1 доллар. При согласии клиента на предлагаемые условия он принесет в банк 10 долларов.\n",
    "\n",
    "Если вы всё прослушали на экономике, то напомним, что выручка — это сколько денег нам принесли клиенты, а прибыль — выручка за вычетом расходов на зарплату и прочее.\n",
    "\n",
    "Загрузите данные о телемаркетинге из предыдущего блока заданий. В этой части не нужно делить выборку - мы будем использовать кросс-валидацию. Используйте 5 фолдов, сделайте `shuffle=True, random_state=500`. По кросс-валидации у вас получится 5 вариантов обучающей и тестовой выборки. Обучите логистическую регрессию на каждой обучающей выборке (воспользуйтесь one-hot для категориальных признаков, гиперпараметры оставьте со значениями по умолчанию) и сделайте предсказания для соответствующих тестовых выборок. Допустим, всем положительным прогнозам ваши сотрудники решили позвонить. Посчитайте на всех тестовых выборках выручку и усредните. Сколько денег вы в среднем заработаете? Также вычислите стандартное отклонение.\n",
    "\n",
    "Сколько из заработанных денег придётся отдать операторам вашего колл-центра?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{DATA_PATH}/bank-additional-full.csv', sep=';')\n",
    "\n",
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внесем некоторую долю случайности. Пусть теперь согласный на условия клиент будет приносить не 10 долларов, а случайную величину, равномерно распределенную в интервале $[0;20)$. Проделайте все те же самые действия. Для имитации реальной ситуации **НЕ** фиксируйте `random_seed` при подсчете выручки с клиента. Что получилось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настройте по кросс-валидации коэффициент регуляризации модели для максимизации прибыли (считайте как случайную величину выше). Удалось ли получить какой-то выигрыш? При каком коэффициенте регуляризациии прибыль максимальна? Постройте график зависимости ожидаемой прибыли от коэффициента, также укажите стандартные отклонения (вам поможет `plt.errorbar`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте запустить перебор несколько раз. Находится ли каждый раз один и тот же \"лучший\" коэффициент? Присутствует ли какая-то закономерность? Какие вы можете сделать из этого выводы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 12 (1 балл).__ Выше мы уже описали примерную экономическую модель вашей задачи. Как вы считаете, что для вашего бизнеса важнее — хороший precision или recall модели? Почему?\n",
    "\n",
    "__Ответ:__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним, что на самом деле логистическая регрессия предсказывает нам вероятности положительного класса для объекта. Возможно, путем настройки порога бинаризации этих вероятностей мы сможем получить какой-то выигрыш? Проверьте ваши рассуждения выше с помощью настройки порога бинаризации на кросс-валидации для максимизации прибыли. Воспользуйтесь сеткой от 0 до 1 с шагом 0.01. Напомним, что снижение порога дает нам более высокий recall и более низкий precision, и наоборот."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте график зависимости прибыли от порога бинаризации, также отметьте на нем стандартные отклонения. Выделите наилучший порог. \n",
    "\n",
    "\n",
    "__Вопрос:__ Замечаете ли вы какую-то закономерность? Для правильного ответа на этот вопрос попробуйте запустить несколько раз и задумайтесь, почему порог получается в какой-то конкретной области?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каковы значения precision и recall на выбранном пороге? Оцените по кросс-валидации. Также вычислите стандартное отклонение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы, вероятно, уже поняли, ваша модель склоняется к более высокому recall. Попробуйте оценить качество модели с помощью `PR-AUC` в зоне recall $\\geq$ 0.5. Сделайте это следующим образом - выберите только те пороги, на которых достигается необходимый recall, затем интерпретируйте отсеченный в единичном квадрате прямоугольник как новый единичный квадрат и посчитайте площадь под отсеченной кривой. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
